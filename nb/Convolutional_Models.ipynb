{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e41624a-91c2-4819-8820-5f109c7bbec4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pz estimation from images "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a2819-5c6c-4dd9-8daf-e14b37cf16ad",
   "metadata": {},
   "source": [
    "First, this notebook shows where to get the data and the required pre processing. \n",
    "\n",
    "Then, it contains the results of the different convolutional models exploration:\n",
    "- CNN\n",
    "- ResNet\n",
    "- DenseNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b902181-7f48-4515-9979-f5cbb827af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#Checking for GPU access\n",
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "  print('WARNING: GPU device not found.')\n",
    "else:\n",
    "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b52da-0a2f-4d54-95ec-4491bebdaf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#tools contains different useful functions (plot results, calculate metrics, etc.)\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a17751-b0d1-4016-b2dc-df3f6e771e9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed5205c-3542-43c5-892f-a3055103864f",
   "metadata": {},
   "source": [
    "The main datafile is the one called 'download'. It contains a collection of galaxy images associated with a catalogue of features (including the redshift). \n",
    "The two other file 'img_30k.npy' and 'z_30k.npy' are just an extracted subset of the 'download' fulldata set for easier manipulation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab3d9b-4e56-448b-a48c-936e7eb47319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is stored in the following repo\n",
    "%ls /global/cfs/cdirs/lsst/groups/PZ/valentin_image_data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a19b5-ad17-404b-b95d-f54d2a27064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/global/cfs/cdirs/lsst/groups/PZ/valentin_image_data_temp/download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4b278-e2d1-4425-aac4-939d4e8bdcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a38588-8d41-4687-99a4-57b261160be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b8d2e5-9c70-4e12-ad4c-a018f795eaf7",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f4591-2ec4-4102-b802-027a3727aa7d",
   "metadata": {},
   "source": [
    "'labels' is a big catalogue containing multiple features for each galawy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad3aa0-9bcd-47c2-9d76-202b94f14f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's extract the first 30k lines and create a Dataframe with them\n",
    "cat = pd.DataFrame(data[\"labels\"][:30000] )\n",
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5866e2-775c-4560-ad79-141768cb44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = cat.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0449fdf-9d03-4ab5-b0c0-ae316c9cc67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.z.min(), cat.z.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b5ad1-e647-4fdb-8582-ebf6a3ff6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cat.z, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62629a9d-6392-411d-9bf1-89ad94ff980d",
   "metadata": {},
   "source": [
    "Redshifts are relatively low in this dataset: 0 < z < 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e3d8a9-3dfb-483f-ad35-831dcc44d06a",
   "metadata": {},
   "source": [
    "### Cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f9f20-d9b1-4c3a-880a-aa3b24c704aa",
   "metadata": {},
   "source": [
    "'cube' contains all galaxy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e9f0c-5815-4892-a383-85581c490e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = data['cube'][:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc972d68-d1f3-4e86-98f1-917bb68b8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8ebdfe-8ddc-4a11-9660-55fe0972ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the images, 3 channels and not 5 are required, hence the :3 at the end\n",
    "plt.imshow(images[0, :, :,:3])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334c80a2-065d-462b-b5b9-8badce4c77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checl the distribution of each channels\n",
    "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
    "    plt.hist(images[...,i].flatten(), 100, label=b, alpha=0.5)\n",
    "    plt.yscale('log');\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec90548-c97b-457f-9fe0-c2e402d270a5",
   "metadata": {},
   "source": [
    "Need to standardize the data.\n",
    "The following data processing is the one proposed by [Francois Lanusse here.](https://github.com/EiffL/Tutorials/blob/master/PhotozCNN/photoz_inference_training_solution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ac532-f14f-4f41-b088-0824078dbac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the noise standard deviation in each band, and apply range compression accordingly\n",
    "from astropy.stats import mad_std\n",
    "scaling = []\n",
    "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
    "    plt.hist(images[...,i].flatten(), 100, label=b, alpha=0.5, range=[-1,1]);\n",
    "    sigma = mad_std(images[...,i].flatten())\n",
    "    scaling.append(sigma)\n",
    "    plt.axvline(sigma, color='C%d'%i,alpha=0.5)\n",
    "    plt.axvline(-sigma, color='C%d'%i,alpha=0.5)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf60cbf-2dae-492b-a233-e3c505576e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at this distribution if we rescale each band by the standard deviation\n",
    "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
    "    plt.hist(images[...,i].flatten()/scaling[i],100, label=b,alpha=0.5, range=[-10,10]);\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8623379b-079f-4e6f-86cf-a027f07843e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    return np.arcsinh(image / scaling / 3. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d109a8-b2cf-4874-bd52-f14b0c386151",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_img = preprocessing(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403fe08-7e98-49ac-b69e-e0bb0ccd9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
    "    plt.hist(tf.reshape(prepro_img[1000, :, :,i], -1), 100, label=b, alpha=0.5)\n",
    "    plt.yscale('log');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0526bbb6-f23c-420f-9840-7d837803e4d2",
   "metadata": {},
   "source": [
    "### Train val test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116fe198-7e30-4b8a-b11c-a5c79e1c104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "img_train = prepro_img[:15000,...]\n",
    "img_val = prepro_img[15000:20000,...]\n",
    "img_test = prepro_img[20000:, ...]\n",
    "\n",
    "z_train = z[:15000]\n",
    "z_val = z[15000:20000]\n",
    "z_test = z[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc42ec-38f8-4b7d-971c-b306ecc60b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd5411-7145-4348-8111-3c15235b885e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c841bd98-bedd-472a-a900-859d48e0955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as tfk\n",
    "\n",
    "def create_model():\n",
    "    model = tfk.models.Sequential()\n",
    "    \n",
    "    model.add(tfk.layers.Conv2D(32, kernel_size=5, padding='same', input_shape=(64,64,5), activation='elu', strides=2))\n",
    "    model.add(tfk.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tfk.layers.Conv2D(64, kernel_size=3, padding='same', activation='elu'))\n",
    "    model.add(tfk.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tfk.layers.Conv2D(128, kernel_size=3, padding='same', strides=2, activation='elu'))\n",
    "    model.add(tfk.layers.BatchNormalization())  \n",
    "\n",
    "    model.add(tfk.layers.Conv2D(256, kernel_size=3, padding='same', activation='elu', strides=2))\n",
    "    model.add(tfk.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tfk.layers.Conv2D(512, kernel_size=3, padding='same', activation='elu', strides=2))\n",
    "    model.add(tfk.layers.BatchNormalization())\n",
    "    \n",
    "    # remplacer flatten par global pooling potentiellment moins d'overfit\n",
    "    model.add(tfk.layers.Flatten())\n",
    "    model.add(tfk.layers.Dense(512))\n",
    "    model.add(tfk.layers.Activation('relu'))\n",
    "    model.add(tfk.layers.Dense(256))\n",
    "    model.add(tfk.layers.Activation('relu'))\n",
    "    model.add(tfk.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', # learning rate will be set by LearningRateScheduler\n",
    "                loss=tfk.metrics.mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a9d5c-6935-4f7f-8fc5-dd1fab03dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c483bde-c708-4d91-b451-4985a51d9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac170353-fafa-44d5-aa7e-3623d8dd98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate schedule\n",
    "LEARNING_RATE=0.001\n",
    "LEARNING_RATE_EXP_DECAY=1\n",
    "lr_decay = tfk.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: LEARNING_RATE * LEARNING_RATE_EXP_DECAY**epoch)\n",
    "\n",
    "# Tensoboard tracking\n",
    "#tb_callback = tf.keras.callbacks.TensorBoard('./logs/CNN', update_freq='batch')\n",
    "\n",
    "# Early_stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "history_cnn = model.fit(x = img_train, \n",
    "          y = z_train,\n",
    "          batch_size = 64,\n",
    "          validation_data=(img_val, z_val),\n",
    "          steps_per_epoch=len(img_train)//64,\n",
    "          epochs=50,\n",
    "          callbacks=[lr_decay, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb15182-abbd-4331-8295-c9c8faac36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction\n",
    "preds = model.predict(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c718a-2602-4bf0-ad6f-5fc8b19d4ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics results\n",
    "dz, pred_bias, smad, out_frac = metrics(z_test, preds.squeeze())\n",
    "print_metrics(pred_bias, smad, out_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26818eb5-8fdc-496f-8982-b398c5af7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plot(history_cnn, 'CNN Model Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c03bc0-5758-455a-8e89-edc4f367db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(z_test, preds.squeeze(), pred_bias, out_frac, smad, 'CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba3521-a5fa-4ccf-b1b6-93aafecc0a8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f1896-b1fc-41ca-83dd-65e9827f97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "def resnet_model():\n",
    "\n",
    "    model = tfk.models.Sequential()\n",
    "\n",
    "    model.add(ResNet50(include_top = False,\n",
    "                     pooling = 'avg',\n",
    "                     input_shape=(64,64,5),\n",
    "                     weights=None))\n",
    "\n",
    "    model.add(tfk.layers.Flatten())\n",
    "    model.add(tfk.layers.Dense(512))\n",
    "    model.add(tfk.layers.Activation('relu'))\n",
    "    model.add(tfk.layers.Dense(256))\n",
    "    model.add(tfk.layers.Activation('relu'))\n",
    "    model.add(tfk.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', # learning rate will be set by LearningRateScheduler\n",
    "                loss=tfk.metrics.mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062bdee-1a7b-4d32-981d-27b381c46300",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = resnet_model()\n",
    "\n",
    "model_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50cbde5-b0a7-4a29-a4ac-67922573da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Learning rate schedule\n",
    "LEARNING_RATE=0.001\n",
    "LEARNING_RATE_EXP_DECAY=0.9\n",
    "lr_decay = tfk.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: LEARNING_RATE * LEARNING_RATE_EXP_DECAY**epoch,\n",
    "    verbose=True)\n",
    "\n",
    "# Tensoboard tracking\n",
    "#tb_callback = tf.keras.callbacks.TensorBoard('./logs/ResNet', update_freq='batch')\n",
    "\n",
    "# Early_stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "history_resnet = model_resnet.fit(x = img_train, \n",
    "          y = z_train,\n",
    "          batch_size = 64,\n",
    "          validation_data=(img_val, z_val),\n",
    "          steps_per_epoch=len(img_train)//64,\n",
    "          epochs=50,\n",
    "          callbacks=[lr_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23709a2-1d48-41bf-8521-bf520e5d697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction\n",
    "resnet_preds = model_resnet.predict(img_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0797fff9-3319-4b9b-9219-55875fc06e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics results\n",
    "dz, pred_bias, smad, out_frac = metrics(z_test, resnet_preds)\n",
    "print_metrics(pred_bias, smad, out_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc9446-2109-43b4-9078-ad80ea800f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plot(history_resnet, 'ResNet Model Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26fd622-7bb4-4f06-83e8-a4bfac84c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(z_test, resnet_preds, pred_bias, out_frac, smad, 'ResNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303d8eaf-84be-48b2-8d62-5ac6e0f84c1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f832b-ecaa-4975-8121-49349a08d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "def densenet_model():\n",
    "\n",
    "    model = tfk.models.Sequential()\n",
    "\n",
    "    model.add(DenseNet121(include_top = False,\n",
    "                     pooling = 'avg',\n",
    "                     input_shape=(64,64,5),\n",
    "                     weights=None))\n",
    "\n",
    "    model.add(tfk.layers.Flatten())\n",
    "    model.add(tfk.layers.Dense(512))\n",
    "    model.add(tfk.layers.Activation('relu'))\n",
    "    model.add(tfk.layers.Dense(256))\n",
    "    model.add(tfk.layers.Activation('relu'))\n",
    "    model.add(tfk.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', # learning rate will be set by LearningRateScheduler\n",
    "                loss=tfk.metrics.mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff64d171-65d7-4f8e-b994-98c52045d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_densenet = densenet_model()\n",
    "\n",
    "model_densenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b7bed-3085-4e90-9a09-24533e35b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Learning rate schedule\n",
    "LEARNING_RATE=0.001\n",
    "LEARNING_RATE_EXP_DECAY=0.9\n",
    "lr_decay = tfk.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: LEARNING_RATE * LEARNING_RATE_EXP_DECAY**epoch,\n",
    "    verbose=True)\n",
    "\n",
    "# Tensoboard tracking\n",
    "#tb_callback = tf.keras.callbacks.TensorBoard('./logs/DenseNet', update_freq='batch')\n",
    "\n",
    "\n",
    "# Early_stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "history_dense = model_densenet.fit(x = img_train, \n",
    "          y = z_train,\n",
    "          batch_size = 64,\n",
    "          validation_data=(img_val, z_val),\n",
    "          steps_per_epoch=len(img_train)//64,\n",
    "          epochs=50,\n",
    "          callbacks=[lr_decay, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefb110-3af6-4705-932a-31382365ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction\n",
    "densenet_preds = model_densenet.predict(img_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c72fb2-19c5-4b52-a22d-6a3a6c9e539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics results\n",
    "dz, pred_bias, smad, out_frac = metrics(z_test, densenet_preds)\n",
    "print_metrics(pred_bias, smad, out_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6fc05-3e1b-4cc3-95b4-7abd8c4ade5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plot(history_dense, 'DenseNet Model Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ee2eb-af95-4a80-b92d-b843e75b57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(z_test, densenet_preds, pred_bias, out_frac, smad, 'DenseNet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f6360d0acf45bf0b1d3617497dbdfbcbdfb4334b88a4110538877fe5548438f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
